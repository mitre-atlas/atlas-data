---

- &ml_model_access
  id: AML.TA0000
  name: ML Model Access
  object-type: tactic
  description: |
    The adversary is attempting to gain some level of access to a machine learning model.

    ML Model Access enables techniques that use various types of access to the machine learning model that can be used by the adversary to gain information, develop attacks, and as a means to input data to the model.
    The level of access can range from the full knowledge of the internals of the model to access to the physical environment where data is collected for use in the machine learning model.
    The adversary may use varying levels of model access during the course of their attack, from staging the attack to impacting the target system.

    Access to an ML model may require access to the system housing the model, the model may be publically accessible via an API, or it may be accessed indirectly via interaction with a product or service that utilizes ML as part of its processes.

- &ml_attack_staging
  id: AML.TA0001
  name: ML Attack Staging
  object-type: tactic
  description: |
    The adversary is leveraging their knowledge of and access to the target system to tailor the attack.

    ML Attack Staging consists of techniques adversaries use to prepare their attack on the target ML model.
    Techniques can include training proxy models, poisoning the target model, and crafting adversarial data to feed the target model.
    Some of these techniques can be performed in an offline manor and are thus difficult to mitigate.
    These techniques are often used to achieve the adversary's end goal.

- &reconnaissance
  id: AML.TA0002
  name: Reconnaissance
  object-type: tactic
  ATT&CK-reference:
      id: TA0043
      url: https://attack.mitre.org/tactics/TA0043/
  description: |
    The adversary is trying to gather information about the machine learning system they can use to plan future operations.

    Reconnaissance consists of techniques that involve adversaries actively or passively gathering information that can be used to support targeting.
    Such information may include details of the victim organizations machine learning capabilities and research efforts.
    This information can be leveraged by the adversary to aid in other phases of the adversary lifecycle, such as using gathered information to obtain relevant ML artifacts, targeting ML capabilities used by the victim, tailoring attacks to the particular models used by the victim, or to drive and lead further Reconnaissance efforts.

- &resource_development
  id: AML.TA0003
  name: Resource Development
  object-type: tactic
  ATT&CK-reference:
      id: TA0042
      url: https://attack.mitre.org/tactics/TA0042/
  description: |
    The adversary is trying to establish resources they can use to support operations.

    Resource Development consists of techniques that involve adversaries creating,
    purchasing, or compromising/stealing resources that can be used to support targeting.
    Such resources include machine learning artifacts, infrastructure, accounts, or capabilities.
    These resources can be leveraged by the adversary to aid in other phases of the adversary lifecycle, such as ML Attack Staging.

- &initial_access
  id: AML.TA0004
  name: Initial Access
  object-type: tactic
  ATT&CK-reference:
      id: TA0001
      url: https://attack.mitre.org/tactics/TA0001/
  description: |
    The adversary is trying to gain access to the machine learning system.

    The target system could be a network, mobile device, or an edge device such as a sensor platform.
    The machine learning capabilities used by the system could be local with onboard or cloud-enabled ML capabilities.

    Initial Access consists of techniques that use various entry vectors to gain their initial foothold within the system.

- &execution
  id: AML.TA0005
  name: Execution
  object-type: tactic
  ATT&CK-reference:
      id: TA0002
      url: https://attack.mitre.org/tactics/TA0002/
  description: |
    The adversary is trying to run malicious code embedded in machine learning artifacts or software.

    Execution consists of techniques that result in adversary-controlled code running on a local or remote system.
    Techniques that run malicious code are often paired with techniques from all other tactics to achieve broader goals, like exploring a network or stealing data.
    For example, an adversary might use a remote access tool to run a PowerShell script that does Remote System Discovery.

- &persistence
  id: AML.TA0006
  name: Persistence
  object-type: tactic
  ATT&CK-reference:
      id: TA0003
      url: https://attack.mitre.org/tactics/TA0003/
  description: |
    The adversary is trying to maintain their foothold via machine learning artifacts or software.

    Persistence consists of techniques that adversaries use to keep access to systems across restarts, changed credentials, and other interruptions that could cut off their access.
    Techniques used for persistence often involve leaving behind modified ML artifacts such as poisoned training data or backdoored ML models.

- &defense_evasion
  id: AML.TA0007
  name: Defense Evasion
  object-type: tactic
  ATT&CK-reference:
      id: TA0005
      url: https://attack.mitre.org/tactics/TA0005/
  description: |
    The adversary is trying to avoid being detected by machine learning-enabled security software.

    Defense Evasion consists of techniques that adversaries use to avoid detection throughout their compromise.
    Techniques used for defense evasion include evading ML-enabled security software such as malware detectors.

- &discovery
  id: AML.TA0008
  name: Discovery
  object-type: tactic
  ATT&CK-reference:
      id: TA0007
      url: https://attack.mitre.org/tactics/TA0007/
  description: |
    The adversary is trying to figure out your machine learning environment.

    Discovery consists of techniques an adversary may use to gain knowledge about the system and internal network.
    These techniques help adversaries observe the environment and orient themselves before deciding how to act.
    They also allow adversaries to explore what they can control and what's around their entry point in order to discover how it could benefit their current objective.
    Native operating system tools are often used toward this post-compromise information-gathering objective.

- &collection
  id: AML.TA0009
  name: Collection
  object-type: tactic
  ATT&CK-reference:
      id: TA0009
      url: https://attack.mitre.org/tactics/TA0009/
  description: |
    The adversary is trying to gather machine learning artifacts and other related information relevant to their goal.

    Collection consists of techniques adversaries may use to gather information and the sources information is collected from that are relevant to following through on the adversary's objectives.
    Frequently, the next goal after collecting data is to steal (exfiltrate) the ML artifacts, or use the collected information to stage future operations.
    Common target sources include software repositories, container registries, model repositories, and object stores.

- &exfiltration
  id: AML.TA0010
  name: Exfiltration
  object-type: tactic
  ATT&CK-reference:
      id: TA0010
      url: https://attack.mitre.org/tactics/TA0010/
  description: |
    The adversary is trying to steal machine learning artifacts or other information about the machine learning system.

    Exfiltration consists of techniques that adversaries may use to steal data from your network.
    Data may be stolen for it's valuable intellectual property, or for use in staging future operations.

    Techniques for getting data out of a target network typically include transferring it over their command and control channel or an alternate channel and may also include putting size limits on the transmission.

- &impact
  id: AML.TA0011
  name: Impact
  object-type: tactic
  ATT&CK-reference:
      id: TA0040
      url: https://attack.mitre.org/tactics/TA0040/
  description: |
    The adversary is trying to manipulate, interrupt, erode confidence in, or destroy your machine learning systems and data.

    Impact consists of techniques that adversaries use to disrupt availability or compromise integrity by manipulating business and operational processes.
    Techniques used for impact can include destroying or tampering with data.
    In some cases, business processes can look fine, but may have been altered to benefit the adversaries' goals.
    These techniques might be used by adversaries to follow through on their end goal or to provide cover for a confidentiality breach.

- &privilege_escalation
  id: AML.TA0012
  name: Privilege Escalation
  object-type: tactic
  ATT&CK-reference:
      id: TA0004
      url: https://attack.mitre.org/tactics/TA0004/
  description: |
    The adversary is trying to gain higher-level permissions.

    Privilege Escalation consists of techniques that adversaries use to gain higher-level permissions on a system or network. Adversaries can often enter and explore a network with unprivileged access but require elevated permissions to follow through on their objectives. Common approaches are to take advantage of system weaknesses, misconfigurations, and vulnerabilities. Examples of elevated access include:
    - SYSTEM/root level
    - local administrator
    - user account with admin-like access
    - user accounts with access to specific system or perform specific function

    These techniques often overlap with Persistence techniques, as OS features that let an adversary persist can execute in an elevated context.

- &credential_access
  id: AML.TA0013
  name: Credential Access
  object-type: tactic
  ATT&CK-reference:
      id: TA0006
      url: https://attack.mitre.org/tactics/TA0006/
  description: |
    The adversary is trying to steal account names and passwords.

    Credential Access consists of techniques for stealing credentials like account names and passwords. Techniques used to get credentials include keylogging or credential dumping. Using legitimate credentials can give adversaries access to systems, make them harder to detect, and provide the opportunity to create more accounts to help achieve their goals.
